{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu các URL vào file rent_urls.txt\n"
     ]
    }
   ],
   "source": [
    "# crawl link rent\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Khởi tạo một danh sách để lưu trữ các URL\n",
    "all_urls = []\n",
    "\n",
    "# Sử dụng vòng lặp để duyệt qua các trang\n",
    "for i in range(1, 5):\n",
    "    # Khởi tạo trình duyệt Chrome\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    url = f'https://batdongsan.com.vn/nha-dat-cho-thue/p{i}'\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        # Chờ cho tất cả các phần tử có class là \"js__product-link-for-product-id\" xuất hiện\n",
    "        link_elements = WebDriverWait(driver, 5).until(\n",
    "            EC.visibility_of_all_elements_located((By.CLASS_NAME, 'js__product-link-for-product-id'))\n",
    "        )\n",
    "\n",
    "        # Lặp qua các phần tử và lấy URL của từng phần tử\n",
    "        for link_element in link_elements:\n",
    "            link_url = link_element.get_attribute('href')\n",
    "            # Thêm URL vào danh sách\n",
    "            all_urls.append(link_url)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "    \n",
    "    # Đóng trình duyệt\n",
    "    driver.quit()\n",
    "\n",
    "# Ghi các URL vào một file văn bản\n",
    "file_path = \"rent_urls.txt\"\n",
    "with open(file_path, \"w\") as file:\n",
    "    for url in all_urls:\n",
    "        file.write(url + \"\\n\")\n",
    "\n",
    "print(\"Đã lưu các URL vào file rent_urls.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu các URL vào file buy_urls.txt\n"
     ]
    }
   ],
   "source": [
    "# crawl link - buy\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Khởi tạo một danh sách để lưu trữ các URL\n",
    "all_urls = []\n",
    "\n",
    "# Sử dụng vòng lặp để duyệt qua các trang\n",
    "for i in range(1, 5):\n",
    "    # Khởi tạo trình duyệt Chrome\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    url = f'https://batdongsan.com.vn/nha-dat-ban/p{i}'\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        # Chờ cho tất cả các phần tử có class là \"js__product-link-for-product-id\" xuất hiện\n",
    "        link_elements = WebDriverWait(driver, 5).until(\n",
    "            EC.visibility_of_all_elements_located((By.CLASS_NAME, 'js__product-link-for-product-id'))\n",
    "        )\n",
    "\n",
    "        # Lặp qua các phần tử và lấy URL của từng phần tử\n",
    "        for link_element in link_elements:\n",
    "            link_url = link_element.get_attribute('href')\n",
    "            # Thêm URL vào danh sách\n",
    "            all_urls.append(link_url)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "    \n",
    "    # Đóng trình duyệt\n",
    "    driver.quit()\n",
    "\n",
    "# Ghi các URL vào một file văn bảnư\n",
    "file_path = \"buy_urls.txt\"\n",
    "with open(file_path, \"w\") as file:\n",
    "    for url in all_urls:\n",
    "        file.write(url + \"\\n\")\n",
    "\n",
    "print(\"Đã lưu các URL vào file buy_urls.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawl data - cho thuê\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "\n",
    "# Định nghĩa hàm để lấy dữ liệu từ một trang cụ thể\n",
    "def extract_data_from_page(driver, url):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Chờ cho các phần tử hiển thị\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.visibility_of_element_located((By.CLASS_NAME, \"re__pr-specs-content\"))\n",
    "        )\n",
    "        \n",
    "        # Trích xuất thông tin từ các phần tử\n",
    "        def get_element_text(elements):\n",
    "            if elements:\n",
    "                return elements[0].text\n",
    "            else:\n",
    "                return \"null\"\n",
    "\n",
    "        price_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Mức giá']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        area_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Diện tích']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        bedroom_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Số phòng ngủ']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        toilet_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Số toilet']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        direct_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Hướng nhà']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        law_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Pháp lý']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        floor_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Số tầng']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        width_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Mặt tiền']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        address_element = driver.find_element(By.CLASS_NAME, \"re__pr-short-description\")\n",
    "        title_element = driver.find_element(By.CLASS_NAME, \"re__pr-title\")\n",
    "        image_elements = driver.find_elements(By.CSS_SELECTOR, \"div.re__overlay.js__overlay img.pr-img\")\n",
    "        description_element = driver.find_element(By.CSS_SELECTOR, \"div.re__section-body.re__detail-content.js__section-body.js__pr-description.js__tracking\")\n",
    "        \n",
    "        try:\n",
    "            type_element = driver.find_element(By.XPATH, \"//li[contains(@class, 'lv1') and contains(@class, 're__actived')]/a\")\n",
    "            type_real_estate = type_element.get_attribute(\"innerHTML\").strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting type: {str(e)}\")\n",
    "            type_real_estate = \"null\"\n",
    "        \n",
    "        # Lấy giá trị của các phần tử hoặc gán \"null\" nếu không tồn tại\n",
    "        price = get_element_text(price_elements)\n",
    "        area = get_element_text(area_elements)\n",
    "        description = description_element.get_attribute(\"innerHTML\").strip()\n",
    "        bedroom = get_element_text(bedroom_elements)\n",
    "        toilet = get_element_text(toilet_elements)\n",
    "        direct = get_element_text(direct_elements)\n",
    "        law = get_element_text(law_elements)\n",
    "        floor = get_element_text(floor_elements)\n",
    "        width = get_element_text(width_elements)\n",
    "        address = address_element.text\n",
    "        title = title_element.text\n",
    "        if image_elements:\n",
    "            image = image_elements[0].get_attribute(\"src\")\n",
    "        else:\n",
    "            image = None\n",
    "        \n",
    "        \n",
    "        # Trả về dữ liệu thu thập được từ trang\n",
    "        return {       \n",
    "            \"title\": title,\n",
    "            \"address\": address,\n",
    "            \"price\": price,\n",
    "            \"area\": area,\n",
    "            \"type\": \"Cho Thuê\",\n",
    "            \"description\": description,\n",
    "            \"bedroom\": bedroom,\n",
    "            \"toilet\": toilet,\n",
    "            \"direction\": direct,\n",
    "            \"law\": law,\n",
    "            \"floor\": floor,\n",
    "            \"width\": width,\n",
    "            \"type_estate\": type_real_estate,\n",
    "            \"image_links\": image\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing URL {url}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "# Đọc các URL từ tệp urls.txt\n",
    "urls_file_path = \"rent_urls.txt\"\n",
    "with open(urls_file_path, \"r\") as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "# Khởi tạo danh sách để lưu trữ dữ liệu thu thập được từ các trang\n",
    "data_list = []\n",
    "\n",
    "# Thu thập dữ liệu từ mỗi URL\n",
    "for url in urls:\n",
    "    # Khởi tạo trình duyệt Chrome\n",
    "    driver = webdriver.Chrome()\n",
    "    url = url.strip()  # Loại bỏ ký tự xuống dòng và khoảng trắng từ URL\n",
    "    data = extract_data_from_page(driver, url)\n",
    "    if data:\n",
    "        data_list.append(data)\n",
    "\n",
    "    # Đóng trình duyệt\n",
    "    driver.quit()\n",
    "\n",
    "# Ghi dữ liệu vào tệp JSON\n",
    "output_file_path = \"rent_data.json\"\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(data_list, file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawl data - bán\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "\n",
    "# Định nghĩa hàm để lấy dữ liệu từ một trang cụ thể\n",
    "def extract_data_from_page(driver, url):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Chờ cho các phần tử hiển thị\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.visibility_of_element_located((By.CLASS_NAME, \"re__pr-specs-content\"))\n",
    "        )\n",
    "        \n",
    "        # Trích xuất thông tin từ các phần tử\n",
    "        def get_element_text(elements):\n",
    "            if elements:\n",
    "                return elements[0].text\n",
    "            else:\n",
    "                return \"null\"\n",
    "\n",
    "        price_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Mức giá']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        area_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Diện tích']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        bedroom_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Số phòng ngủ']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        toilet_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Số toilet']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        direct_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Hướng nhà']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        law_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Pháp lý']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        floor_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Số tầng']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        width_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 're__pr-specs-content-item-title') and text()='Mặt tiền']/following-sibling::span[@class='re__pr-specs-content-item-value']\")\n",
    "        address_element = driver.find_element(By.CLASS_NAME, \"re__pr-short-description\")\n",
    "        title_element = driver.find_element(By.CLASS_NAME, \"re__pr-title\")\n",
    "        image_elements = driver.find_elements(By.CSS_SELECTOR, \"div.re__overlay.js__overlay img.pr-img\")\n",
    "        description_element = driver.find_element(By.CSS_SELECTOR, \"div.re__section-body.re__detail-content.js__section-body.js__pr-description.js__tracking\")\n",
    "        \n",
    "        try:\n",
    "            type_element = driver.find_element(By.XPATH, \"//li[contains(@class, 'lv1') and contains(@class, 're__actived')]/a\")\n",
    "            type_real_estate = type_element.get_attribute(\"innerHTML\").strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting type: {str(e)}\")\n",
    "            type_real_estate = \"null\"\n",
    "        \n",
    "        # Lấy giá trị của các phần tử hoặc gán \"null\" nếu không tồn tại\n",
    "        price = get_element_text(price_elements)\n",
    "        area = get_element_text(area_elements)\n",
    "        description = description_element.get_attribute(\"innerHTML\").strip()\n",
    "        bedroom = get_element_text(bedroom_elements)\n",
    "        toilet = get_element_text(toilet_elements)\n",
    "        direct = get_element_text(direct_elements)\n",
    "        law = get_element_text(law_elements)\n",
    "        floor = get_element_text(floor_elements)\n",
    "        width = get_element_text(width_elements)\n",
    "        address = address_element.text\n",
    "        title = title_element.text\n",
    "        if image_elements:\n",
    "            image = image_elements[0].get_attribute(\"src\")\n",
    "        else:\n",
    "            image = None\n",
    "        \n",
    "        \n",
    "        # Trả về dữ liệu thu thập được từ trang\n",
    "        return {       \n",
    "            \"title\": title,\n",
    "            \"address\": address,\n",
    "            \"price\": price,\n",
    "            \"area\": area,\n",
    "            \"type\": \"Mua Bán\",\n",
    "            \"description\": description,\n",
    "            \"bedroom\": bedroom,\n",
    "            \"toilet\": toilet,\n",
    "            \"direction\": direct,\n",
    "            \"law\": law,\n",
    "            \"floor\": floor,\n",
    "            \"width\": width,\n",
    "            \"type_estate\": type_real_estate,\n",
    "            \"image_links\": image\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing URL {url}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "# Đọc các URL từ tệp urls.txt\n",
    "urls_file_path = \"buy_urls.txt\"\n",
    "with open(urls_file_path, \"r\") as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "# Khởi tạo danh sách để lưu trữ dữ liệu thu thập được từ các trang\n",
    "data_list = []\n",
    "\n",
    "# Thu thập dữ liệu từ mỗi URL\n",
    "for url in urls:\n",
    "    # Khởi tạo trình duyệt Chrome\n",
    "    driver = webdriver.Chrome()\n",
    "    url = url.strip()  # Loại bỏ ký tự xuống dòng và khoảng trắng từ URL\n",
    "    data = extract_data_from_page(driver, url)\n",
    "    if data:\n",
    "        data_list.append(data)\n",
    "\n",
    "    # Đóng trình duyệt\n",
    "    driver.quit()\n",
    "\n",
    "# Ghi dữ liệu vào tệp JSON\n",
    "output_file_path = \"buy_data.json\"\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(data_list, file, ensure_ascii=False, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pr-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
